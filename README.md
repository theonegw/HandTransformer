## ğŸŒŸç®€ä»‹
è¿™æ˜¯ä¸€ä»½æ‰‹åŠ¨å®ç°çš„ Transfomer æ¨¡å‹ï¼Œå…¶ä¸­åŒ…å« multi-head self-attentionã€position-wise FFNã€æ®‹å·®ç½‘ç»œ+LayerNormå’Œä½ç½®ç¼–ç ã€‚æœ¬æ¬¡é¡¹ç›®æ˜¯åœ¨æ•°æ®é›†`CNN/DailyMail`è¿›è¡Œå®éªŒã€‚
## Project structure
```
handtransformer
â”œâ”€â”€ results
â”‚   â”œâ”€â”€ training_curve.png
â”‚   â”œâ”€â”€ training_loss_curve.png
â”‚   â”œâ”€â”€ validation_rouge1_curve.png
â”‚   â””â”€â”€ validation_rouge2_curve.png
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ test.sh                     # æµ‹è¯•è„šæœ¬
â”‚   â””â”€â”€ train.sh                    # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ modules                     # æ¨¡å‹çš„å„ä¸ªéƒ¨ä»¶
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ DecoderLayer.py         # è§£ç å™¨
â”‚   â”‚   â”œâ”€â”€ EncoderLayer.py         # ç¼–ç å™¨
â”‚   â”‚   â”œâ”€â”€ MultiHeadAttention.py   # å¤šå¤´æ³¨æ„åŠ›
â”‚   â”‚   â”œâ”€â”€ PositionalEncoder.py    # ä½ç½®ç¼–ç 
â”‚   â”‚   â”œâ”€â”€ PositionFeedForward.py  # FFN
â”‚   â”œâ”€â”€ data_loader.py              # æ•°æ®ä¸‹è½½
â”‚   â”œâ”€â”€ model.py                    # æ¨¡å‹å®šä¹‰
â”‚   â””â”€â”€ utils.py                    # æŸå¤±å‡½æ•°å’Œå…¶ä»–è¾…åŠ©å‡½æ•°
â”œâ”€â”€ README.md       
â”œâ”€â”€ requirements.txt                # ä¾èµ–åº“
â”œâ”€â”€ test.py                         # æµ‹è¯•å‡½æ•°
â””â”€â”€ train.py                        # è®­ç»ƒå‡½æ•°
```
## ğŸ› ï¸Installation
### Prerequires
+ Linux
+ python=3.9
+ pytoch
+ CUDA=12.0
### Required Libraries
+ datasets
+ transformers
+ matplotlib
+ numpy<2.0
+ evaluate
+ rouge_score

### Environment Setup
å…‹éš†é¡¹ç›®
```bash
git clone https://github.com/theonegw/HandTransformer
```
**Setp1:** ä¸‹è½½[miniconda](https://www.anaconda.com/docs/getting-started/miniconda/main)ã€‚

æˆ–è€…ä½¿ç”¨å‘½ä»¤
```bash
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh
```

**Setp2:** æ„å»ºcondaç¯å¢ƒåŒæ—¶æ¿€æ´»ã€‚
```bash
conda create -n handtransformer python=3.9  
conda activate handtransformer
```
**Setp3:** ä¸‹è½½ [pytorch](https://pytorch.org/get-started/previous-versions/) ç‰ˆæœ¬
```bash
conda install pytorch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 pytorch-cuda=12.1 -c pytorch -c nvidia
```
**Setp4:** ä¸‹è½½ç¯å¢ƒæ‰€éœ€åº“
```bash
pip install -r requirements.txt
```
## ğŸ‹ï¸Training
### æ•°æ®é›†ä¸‹è½½
ä½¿ç”¨çš„æ•°æ®é›†ä¸º`CNN/DailyMail`ï¼Œé€šè¿‡ä½¿ç”¨datasetsåº“ä¸‹è½½çš„ï¼š
```python
dataset = load_dataset("cnn_dailymail", "3.0.0")
```
è®­ç»ƒæ—¶ä¼šè‡ªåŠ¨ä¸‹è½½ï¼Œå¦‚æœä¸‹è½½å¤±è´¥å¯ä»¥è‡ªå·±ä»ç½‘ä¸Šä¸‹è½½ã€‚
### è®­ç»ƒ
è¿è¡Œè®­ç»ƒè„šæœ¬ `scripts/train.sh`
```bash
sh scripts/train.sh
```

æˆ–è€…ç›´æ¥ä½¿ç”¨
```bash
CUDA_VISIBLE_DEVICES=7 python train.py \
    --d_model 128 \
    --num_heads 8 \
    --num_layers 2 \
    --d_ff 512 \
    --batch_size 32 \
    --learning_rate 3e-4 \
    --epochs 20 \
    --seed 42 \
    --train_subset_size 10000 \
    --val_subset_size 500 \
    --model_save_path "models/hand_transformer.pt"
```
+ `CUDA_VISIBLE_DEVICES`ï¼š æœ¬åœ°ä½¿ç”¨çš„æ˜¾å¡ç¼–å·
+ `d_model`ï¼šÂ·
+ `num_heads`ï¼šæ³¨æ„åŠ›çš„å¤´æ•°
+ `num_layers`ï¼šencoder-decoderçš„å±‚æ•°
+ `d_ff`ï¼š
+ `learning_rate`ï¼šå­¦ä¹ ç‡
+ `epochs`ï¼šè¿­ä»£æ¬¡æ•°
+ `seed`ï¼šéšæœºç§å­è®¾ç½®ï¼Œç”¨æ¥å¤ç°æ•ˆæœ
+ `train_subset_size`ï¼šæ¯æ¬¡è®­ç»ƒä½¿ç”¨çš„æ•°æ®å¤§å°
+ `val_subset_size`ï¼šæ¯æ¬¡æµ‹è¯•æ‰€ä½¿ç”¨çš„æ•°æ®å¤§å°
+ `model_save_path`ï¼šæ¨¡å‹ä¿å­˜åœ°å€

## ğŸ“ºtest

### æµ‹è¯•
è¿è¡Œæµ‹è¯•è„šæœ¬ `scripts/test.sh`
```bash
sh scripts/test.sh
```
æˆ–è€…ç›´æ¥ä½¿ç”¨
```bash
python test.py \
    --sentence "Weather forecasts predict heavy rain and strong winds moving in from the west, expected to arrive by tomorrow morning." \
    --model_path "models/hand_transformer.pt" 
```
+ `sentence`ï¼šä½ è¦è¿›è¡Œæ‘˜è¦çš„å¥å­
+ `model_path`ï¼šåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
